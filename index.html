<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Yuchen Wang</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>

    <!-- Plugin CSS -->
    <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/creative.css" rel="stylesheet">

    <link rel="shortcut icon" href="img/favicon.ico">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Yuchen Wang</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#project1">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <header class="masthead text-center text-white d-flex">
      <div class="container my-auto">
        <div class="row">
          <div class="col-lg-10 mx-auto mb-5">
            <img src="img//portfolio/avatars/avatar2.jpg" alt="Avatar" class="photo">
          </div>
          <div class="col-lg-10 mx-auto">
            <h1 class="text-uppercase">
              <strong>Yuchen Wang</strong>
            </h1>
            <hr>
          </div>
          <div class="col-lg-8 mx-auto">
            <p class="text-faded mb-0">Master of Science in Robotics|Northwestern University</p>
            <p class="text-faded mb-5">B.S. in Computer Engineering|Rose-Hulman Institute of Technology</p>
            <a class="btn btn-primary btn-xl js-scroll-trigger" href="https://drive.google.com/file/d/1WibVZ7Ql8NgdqxSY-w62z-lbRRiNXNIx/view?usp=sharing">Resume</a>
          </div>
        </div>
      </div>
    </header>

    <section class="bg-primary" id="about">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto text-center">
            <h2 class="section-heading text-white">ABOUT</h2>
            <hr class="light my-4">
            <p class="text-faded mb-4">As the daughter of a pilot, I have a passion on autonomous vehicle and drones.
              And I am always waiting for an opportunity of building the coolest robot and changing the world.
            </p>
            <p class="text-faded mb-4">Graduating December 2019. Actively looking for 2020 full time job.</p>
            <a class="btn btn-light btn-xl js-scroll-trigger" href="https://www.mccormick.northwestern.edu/robotics/meet-students/profiles-2018-2019/wang-yuchen.html">More Info</a>
          </div>
        </div>
      </div>
    </section>

    <section id="skills">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">SKILLS</h2>
            <hr class="my-4">
          </div>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-lg-3 col-md-6 text-center">
            <div class="service-box mt-5 mx-auto">
              <i class="fas fa-4x fa-robot text-primary mb-3 sr-icon-1"></i>
              <h3 class="mb-3">Robotics</h3>
              <p class="text-muted mb-0">Python</p>
              <p class="text-muted mb-0">ROS</p>
              <p class="text-muted mb-0">C/C++</p>
              <p class="text-muted mb-0">Linux</p>
              <p class="text-muted mb-0">PX4</p>
              <p class="text-muted mb-0">Machine Learning</p>
            </div>
          </div>
          <div class="col-lg-3 col-md-6 text-center">
            <div class="service-box mt-5 mx-auto">
              <i class="fas fa-4x fa-code text-primary mb-3 sr-icon-2"></i>
              <h3 class="mb-3">Software Development</h3>
              <p class="text-muted mb-0">Java</p>
              <p class="text-muted mb-0">Embedded System</p>
              <p class="text-muted mb-0">Android Development</p>
              <p class="text-muted mb-0">Web Development</p>
            </div>
          </div>
          <div class="col-lg-3 col-md-6 text-center">
            <div class="service-box mt-5 mx-auto">
              <i class="fas fa-4x fa-car-side text-primary mb-3 sr-icon-3"></i>
              <h3 class="mb-3">Autonomous</h3>
              <p class="text-muted mb-0">Motion Planning</p>
              <p class="text-muted mb-0">Path Planning</p>
              <p class="text-muted mb-0">Control System</p>
              <p class="text-muted mb-0">Computer Vision</p>
              <p class="text-muted mb-0">Sensor Fusion</p>
            </div>
          </div>
          <div class="col-lg-3 col-md-6 text-center">
            <div class="service-box mt-5 mx-auto">
              <i class="fas fa-4x fa-shoe-prints text-primary mb-3 sr-icon-4"></i>
              <h3 class="mb-3">Interests</h3>
              <p class="text-muted mb-0">Cooking</p>
              <p class="text-muted mb-0">Workout</p>
              <p class="text-muted mb-0">EDM</p>
              <p class="text-muted mb-0">Climbing</p>
              <p class="text-muted mb-0">Dancing</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="bg-primary text-white" id="project1">
        <div class="container text-center">
          <h2 class="mb-4">PROJECTS</h2>
        </div>
    </section>

    <section class="p-0">
      <div class="container-fluid p-0">
        <div class="row no-gutters">
          <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal9">
              <img class="img-fluid" src="img/portfolio/fullsize/iris.jpg" alt="">
              <div class="overlay">
                <div class="text">Quadcopter Finger Tracking and Path Planning</div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal11">
                <img class="img-fluid" src="img/portfolio/fullsize/chat.png" alt="">
                <div class="overlay">
                  <div class="text">Conversational AI</div>
                </div>
              </a>
            </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal12">
              <img class="img-fluid" src="img/portfolio/fullsize/rotor.jpg" alt="">
              <div class="overlay">
                <div class="text">Quadrotor Autonomous Control</div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal7">
              <img class="img-fluid" src="img/portfolio/fullsize/baxter_block.jpg" alt="">
              <div class="overlay">
                <div class="text">Baxter Tower Stacking</div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal10">
                <img class="img-fluid" src="img/portfolio/fullsize/kuka_tbn.png" alt="">
                <div class="overlay">
                  <div class="text">KUKA Motion Planning</div>
                </div>
              </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal13">
                <img class="img-fluid" src="img/portfolio/fullsize/pinball.png" alt="">
                <div class="overlay">
                  <div class="text">PinBall Dynamic Simulation</div>
                </div>
              </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal6">
                <img class="img-fluid" src="img/portfolio/fullsize/rrt.jpg" alt="">
                <div class="overlay">
                  <div class="text">RRT Path Planning</div>
                </div>
              </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal1">
              <img class="img-fluid" src="img/portfolio/fullsize/tracker.jpg" alt="">
              <div class="overlay">
                <div class="text">Ball Tracker</div>
              </div>
            </a>
          </div>
          <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal8">
                <img class="img-fluid" src="img/portfolio/fullsize/dermatology.jpg" alt="">
                <div class="overlay">
                  <div class="text">Dermatology Diagnose</div>
                </div>
              </a>
        </div>
          <!-- <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
                <img class="img-fluid" src="img/portfolio/fullsize/butt.jpg" alt="">
                <div class="overlay">
                  <div class="text">Sacral Nerve Stimulator</div>
                </div>
              </a>
          </div> -->
         
          <!-- <div class="col-lg-4 col-sm-6 portfolio-item">
              <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2">
                <img class="img-fluid" src="img/portfolio/fullsize/megabot.jpg" alt="">
                <div class="overlay">
                  <div class="text">MEGABOT Localization</div>
                </div>
              </a>
            </div> -->
          <!-- <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
              <img class="img-fluid" src="img/portfolio/fullsize/field.jpg" alt="">
            </a>
          </div> -->
          <!-- <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
              <img class="img-fluid" src="img/portfolio/fullsize/butt.jpg" alt="">
              <div class="overlay">
                <div class="text">Sacral Nerve Stimulator</div>
              </div>
            </a>
          </div> -->
          <!-- <div class="col-lg-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal5">
              <img class="img-fluid" src="img/portfolio/fullsize/button.jpg" alt="">
            </a>
          </div> -->
        </div>
      </div>
    </section>

    <section class="bg-primary text-white" id="portfolio">
        <div class="container text-center">
          <a class="btn btn-light btn-xl sr-button" href="https://www.youtube.com/channel/UCMW0QI-MZktekRybsIOxTMg?view_as=subscriber">Explore More</a>
        </div>
    </section>

    <section id="contact">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 mx-auto text-center">
            <h2 class="section-heading">CONTACT ME</h2>
            <hr class="my-4">
          </div>
        </div>
        <div class="row">
          <div class="col-lg-4 mr-auto text-center">
            <a href="mailto:yuchn.w@gmail.com">
              <i class="far fa-envelope fa-5x mb-3 sr-contact-1" ></i>
            </a>
          </div>
          <div class="col-lg-4 ml-auto text-center">
            <a href="https://www.linkedin.com/in/yuch3nwang/">
              <i class="fab fa-linkedin-in fa-5x mb-3 sr-contact-2" ></i>
            </a>
          </div>
          <div class="col-lg-4 ml-auto text-center">
            <a href="https://www.facebook.com/yuchwong">
              <i class="fab fa-facebook-f fa-5x mb-3 sr-contact-3" ></i>
            </a>
          </div>
        </div>
      </div>
    </section>

    <!-- Modal 1 -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Ball Tracking System</h2>
                  <p class="item-intro text-muted">MSR Hackathon Project</p>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/bqnysqX-sqw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <p></p>
                  <li>Built a camera-pan-tilt system and programmed in Python to track target objects</li>
                  <li>Implemented image processing with OpenCV</li>
                  <li>Integrated multiple scripts in ROS to subscribe data from web cam and publish instructions to the pan-tilt</li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 2 -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">MEGABOT</h2>
                  <p class="item-intro text-muted">Undergrad Course Project</p>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/ZS9oTac86MY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <p></p>
                  <p>Robot implements mapping, localization and navigation. It’s supposed to explore the 4x4 map and return to the origin location.</p>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/uyw_PsAs-9w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <p></p>
                  <p>Wall following with side sonar sensors using PD-control.</p>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Golf Ball Delivery</h2>
                  <p class="item-intro text-muted">Undergrad Course Project</p>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/xwRn9z_qw0c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/mTAgFG78OJ8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <p></p>
                  <li>Performed accurate GPS detection on a six-wheel and 5-DoF robot with Android device</li>
                  <li>Implemented target seeking with image processing</li>
                  <li>For more details about the project please check <a href="https://docs.google.com/document/d/13WJMJKoB1JREojiy42JXRg4B2b9O12Hy8bIRS7dj4i0/edit?usp=sharing">HERE</a></li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Sacral Nerve Stimulator</h2>
                  <p class="item-intro text-muted">Undergrad Senior Design</p>
                  <img src="img/portfolio/fullsize/sacral.jpg"></img>
                  <p></p>
                  <li>Designed and built an implant nerve stimulator for patients suffering from urine incontinence.</li>
                  <li>Programmed microcontroller in C to generate continuous electrical pulse.</li>
                  <li>Implemented inductive charging to transfer the pulse signal through skin and applied it to nerve.</li>
                  <li>Collaborated with three other ECE senior students and communicated with client in Nepal.</li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 5 -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">Bluetooth Emergency Button</h2>
                  <p class="item-intro text-muted">Undergrad Course Project</p>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/i4mmO1QHRWA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  <p></p>
                  <li>Built a remote pushbutton that could send out emergency text or call once it is pressed.</li>
                  <li>Implemented functionalities in Linux with Twilio API on the BeagleBone Blue board.</li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 6 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">RRT Path Planning</h2>
                  <p class="item-intro text-muted">MSR Hackathon Project</p>
                  <img src="img/portfolio/fullsize/simple.png"></img>
                  <!-- <li>Generate an RRT plot in a 100x100 domain with initial point at center.</li> -->
                  <p>Considering a domain D=[0,100]×[0,100], an initial configuration qinit=(50,50), and a stepsize Δq=1, 
                    used the Euclidean metric for evaluating distance. Then constructed the RRT plot.</p>
                  <img src="img/portfolio/fullsize/circle.png"></img>
                  <!-- <li>Generate an RRT plot with circular obstacles.</li>
                  <li>Start from [10,10] and set goal at [75,75].</li>
                  <li>Highlight the final path.</li> -->
                  <p>Set the starting location at (10,10) and a goal location at (75,75). 
                    For the representation of the environment, assume all things can produce collision are easily represented as circular. 
                    This way, the collision checking can be performed analytically. To determine if a particular pair of vertices has a safe, 
                    collision-free path between them, determine if the line connecting the nodes has an intersection with any of the circles. 
                    The final path used by the RRT to go from the start state to the goal state is clearly highlighted.</p>
                  <p></p>
                  <embed src="https://plot.ly/~yuchnw/9.embed" width="1000" height="1000">
                  <p>This is the updated 3D version of RRT algorithm. The basic idea is still the same as 2D RRT. 
                    After getting a feasible path, I smoothed it to reduce the number of waypoints. 
                    Generally, since the feasible path has been generated from the RRT-grown tree, and it consists of a chain of nodes connections, 
                    the optimization process is conducted by randomly picking up two nodes from the feasible path, and trying to connect them directly.</p>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 7 -->
    <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">BAXTACK: Baxter Tower Stacking</h2>
                  <p class="item-intro text-muted">MSR Course Project</p>
                  <img width="800" height="450" src="img/portfolio/fullsize/baxtack.gif"></img>
                  <p></p>
                  <h3>Objective</h3>
                  <p>The goal of this project is for Baxter to pick different blocks on the table by color and size, and stack them together.</p>
                  <h3>Basic Introduction</h3>
                  <p>The Baxter is able to recognize all the blocks on the table through image processing. The location, size and color information of 
                    the blocks will be passed to the robot and it will calculate the goal position of each movement. The robot arm picks up the largest 
                    block first and places it to a fixed position. Then it repeats the previous step by finding a smaller block and stack it on the previous one.</p>
                  <p>All the blocks were 3D printed, with different size ranging from 2"x2"x2" up to 3"x3"x2". The color of the blocks are either red or yellow.</p>
                  <h3>Computer Vision</h3>
                  <p>Baxter's right hand camera has a decent resolution that works well in the project, so there is no need of using an external web cam. 
                    A node was written to process the raw image data basically using OpenCV library. When the user clicks on the camera image view and picks a color,
                     the node would fetch the RGB value of the pixel being clicked and set a boundary range based on that value (in our case the boundary was
                      ([B-30, G-30, R-30],[B+30, G+30, R+30])). All the contours that matches the RGB boundary would be detected and labeled. Then the contours 
                      will be sorted by area and listed from the largest to the smallest. The node will finally publish a topic containing the center coordinates 
                      of all the contours(sorted by area) in pixel value, and the angles that each contour tilted with respect to x-axis.</p>
                  <img width="800" height="430" src="img/portfolio/fullsize/color_pick.jpg"></img>
                  <h3>Translation from Pixel Coordinate to World Coordinate</h3>
                  <li>Our group is using the baxter right hand camera to capture the blocks' position on the table. Their positions are caculated from the 
                    blocks' pixel coordinates published by the computer vision. The caculation is based on the following function.</li>>
                    <a href="https://www.codecogs.com/eqnedit.php?latex=s\begin{bmatrix}u\\v\\1\end{bmatrix}=\begin{bmatrix}\alpha_x&space;&&space;0&space;&&space;u_0&space;&&space;0\\&space;0&space;&&space;\alpha_y&space;&&space;v_0&space;&&space;0\\&space;0&space;&&space;0&space;&&space;1&space;&&space;0\end{bmatrix}\begin{bmatrix}R&space;&&space;t\\0&space;&&space;0\end{bmatrix}\begin{bmatrix}x_\omega\\&space;y_\omega\\&space;z_\omega\\&space;1\end{bmatrix}=M_1M_2X_\omega" target="_blank"><img src="https://latex.codecogs.com/gif.latex?s\begin{bmatrix}u\\v\\1\end{bmatrix}=\begin{bmatrix}\alpha_x&space;&&space;0&space;&&space;u_0&space;&&space;0\\&space;0&space;&&space;\alpha_y&space;&&space;v_0&space;&&space;0\\&space;0&space;&&space;0&space;&&space;1&space;&&space;0\end{bmatrix}\begin{bmatrix}R&space;&&space;t\\0&space;&&space;0\end{bmatrix}\begin{bmatrix}x_\omega\\&space;y_\omega\\&space;z_\omega\\&space;1\end{bmatrix}=M_1M_2X_\omega" title="s\begin{bmatrix}u\\v\\1\end{bmatrix}=\begin{bmatrix}\alpha_x & 0 & u_0 & 0\\ 0 & \alpha_y & v_0 & 0\\ 0 & 0 & 1 & 0\end{bmatrix}\begin{bmatrix}R & t\\0 & 0\end{bmatrix}\begin{bmatrix}x_\omega\\ y_\omega\\ z_\omega\\ 1\end{bmatrix}=M_1M_2X_\omega" /></a>
                  <li>The intrinsic matrix M_1 is get from the camera calibration using ROS package camera_calibration . 
                    The external matrix  M_2 is obtained from the TF tree from camera to base. Since the table is flat, the z coordinate of the blocks 
                    can be obtained from the IR range sensor in the left hand.</li>
                  <p></p>
                  <h3>Control</h3>
                  <p>Baxter was programmed to begin at the same initial position each time. Then when list of blocks' positions reached, the robot arm would reach at a 
                    certain height over the block, and then the robot arm came down to pick the block. After that, the arm moved to the goal position to put down the blocks.</p>
                  <p>For the robot arm control, Cartesian Path Planner plugin in MoveIt was used to generate waypoints between beginning position and goal position.
                     So that the robot arm won't move in unusual way and avoid hitting obstacles. And then, MoveIi planner was used to generate plan to make 
                     the arm move to the goal position along the waypoints.</p>
                  <p>During the trajection, the range sensor in the left hand was used to detect whether the block was attached to the baxter's left hand successfully or not. 
                    If the distance from left hand was less than 0.1m, the baxter will assume that the block was not picked successfully. 
                    Then in the next placement, the height of the block being placed will remain the same and also the baxter would came to the pick block again, 
                    which were not being picked successfully at last time.</p>
                  <h3>Full Demo Video</h3>
                  <iframe width="640" height="360" src="https://www.youtube.com/embed/SKFFj9aCwcA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <hr>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 8 -->
    <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
              <div class="lr">
                <div class="rl"></div>
              </div>
            </div>
            <div class="container">
              <div class="row">
                <div class="col-lg-12 mx-auto">
                  <div class="modal-body">
                    <!-- Project Details Go Here -->
                    <h2 class="text-uppercase">Dermatology Diagnose</h2>
                    <p class="item-intro text-muted">MSR Machine Learning Project</p>
                    <iframe width="640" height="360" src="https://www.youtube.com/embed/mSXIHDJPfCU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <p></p>
                    <p>This project uses machine learning to help diagnose different types of dermatology diseases, and the probabilty of making a definite diagnosis. The training data has more than 400 instances and each has 34 attributes. The output has six different values, each representing a specific type of dermatology disease.</p>
                    <p>Gradient descent, boosting and multiclass classification are the mainly used methods in this project. Boosting will return the top four important features for diagnosis. A GUI is provided to let user enter all attributes and return the most possible dermatology disease and the probability.</p>
                    <p></p>
                    <img src="img/portfolio/fullsize/gui.jpg"></img>
                    <p></p>
                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                      <i class="fas fa-times"></i>
                      Close Project</button>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

    <!-- Modal 9 -->
    <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
              <div class="lr">
                <div class="rl"></div>
              </div>
            </div>
            <div class="container">
              <div class="row">
                <div class="col-lg-12 mx-auto">
                  <div class="modal-body">
                    <!-- Project Details Go Here -->
                    <h2 class="text-uppercase">Iris Quadcopter Gazebo Simulation</h2>
                    <p class="item-intro text-muted">Individual Project</p>
                    <h3>Autonomous Path Planning</h3>
                    <img width="800" height="434" src="img/portfolio/fullsize/bar-fly.gif"></img>
                    <p></p>
                    <h3>Fingertip Navigation</h3>
                    <img width="800" height="450" src="img/portfolio/fullsize/hand_nav.gif"></img>
                    <hr>
                    <h3>Introduction</h3>
                    <p>This main goal of this project is to simulate the behavior of an Iris quadcopter based on PX4 firmware in a Gazebo world. 
                      The quadcopter is supposed to accomplish an 3D motion planning. At first, the quad will be given a map containing all the obstacles and 
                      a destination point. It will use RRT algorithm to generate an optimized path to reach the goal and avoid collisions. 
                      The whole motion of the drone should be smooth, safe and robust.
                    <p>Other than that, the quad could also be manipulated by hand-gesture to navigate in complex aerial space.</p>
                    <p></p>
                    <h3>PX4</h3>
                    <lp>PX4 is the autopilot control platfrom used in this project. It establishes the connection between ROS and Gazebo simulation via MAVROS. 
                      PX4 supports both Software In the Loop (SITL) simulation, where the flight stack runs on computer (either the same computer or another 
                      computer on the same network) and Hardware In the Loop (HITL) simulation using a simulation firmware on a real flight controller board.</p>
                    <p></p>
                    <h3>MAVROS--MAVLink</h3>
                    <p>MAVROS is a ROS package which provides communication driver for various autopilots with MAVLink communication protocal. 
                      MAVROS can be used to communicate with any MAVLink enabled autopilot, and for this specific project it will be only used to enable 
                      communication between the PX4 flight stack and a ROS enabled companion computer.</p>
                    <p></p>
                    <h3>ROS with Gazebo</h3>
                    <p>ROS can be used with PX4 and the Gazebo simulator. As the picture below indicates, PX4 communicates with Gazebo to receive sensor data from the simulated 
                      world and send motor and actuator values. It communicates with the GCS and ROS to send telemetry from the simulated environment and receive commands.</p>
                    <p></p>
                    <h3>3D-RRT</h3>
                    <embed src="https://plot.ly/~yuchnw/11.embed" width="800" height="800">
                    <p>This is the result of the 3D RRT path planning algorithm. Black lines are all the nodes connections,
                       the green line is the feasible path and the blue line is the optimized path.</p>
                    <p></p>
                    <p>After getting a feasible path(the green one), I smoothed it to reduce the number of waypoints(the blue one).
                       Generally, since the feasible path has been generated from the RRT-grown tree, and it consists of a chain of nodes connections, 
                       the optimization process is conducted by randomly picking up two nodes from the feasible path, and trying to connect them directly.
                        Here is the result of the Optimized Path. It takes a more complicated obstacle environment and applies the RRT algorithm. 
                        The feasible path has 102 waypoints and the number was reduced to 8 after optimization.</p>
                    <p></p>
                    <h3>Pilot</h3>
                    <p>The project is able to take differnt commands to arm, disarm, takeoff, land the quad and return its geographic coordinates. 
                      Also, it can receive the path generated by RRT algorithm and let the quad follow it. Here is the full demo video:</p>
                    <iframe width="640" height="360" src="https://www.youtube.com/embed/zPKlL9mI_Lc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <p></p>
                    <h3>Tracking</h3>
                    <p>First, I used OpenCV to track my hand's movement and find the farthest fingertip. As my hand moves, the fingertip will create a path that could 
                      be used as the desired trajectory for the quad in Gazebo. Since the lightning condition and different skin color would affect the tracking performance a lot,
                       skin color histogram is a useful technique here. The program is taking 900 skin color samples from the user’s hand and then creates a histogram, 
                       using the ROI matrix for the skin color and normalizing this matrix. Then OpenCV will take this histogram to seperate the hand feature from the 
                       image and apply the skin color to the frame. After that, I find the max contour and calculat the centroid and farthest point from the centroid (which is the longest fingertip).</p>
                    <p>ASUS Xtion Pro depth camera is the deviced I used to capture the 3D position of the fingertip. First I calibrated the RGB image with the depth map to make both are
                       coordinate-aligned. Then I run the OpenCV script on the RGB frame to find the X-Y position of the tip, then parse the pixel value to the depth array generated from 
                       the depth camera and get the distance between the fingertip to the lense. As the user moves the hand either far away to the camera or close to it, the quadcopter can 
                      also adjust its altitute respectively.</p>
                    <p></p>
                    <p>Here is the demo of the fingertip tracking result: (to keep the frame clean, only the last 20 fingertip trace would be displayed on the screen)</p>
                    <img width="800" height="640" src="img/portfolio/fullsize/finger.gif"></img>
                    <p>After getting the X-Y coordinate of the fingertip through the RGB image layer, I calibrated it with the depth image layer where could return the distance between 
                      the fingertip and the lense. Then I synced the X-Y-Z trajectory generated by hand detection to the PX4 pilot program, considering the trace of fingertip as waypoints for the quadcopter.</p>
                    <hr>
                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                      <i class="fas fa-times"></i>
                      Close Project</button>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

    <!-- Modal 10 -->
    <div class="portfolio-modal modal fade" id="portfolioModal10" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">KUKA youBot Motion Planning</h2>
                  <p class="item-intro text-muted">Motion Planning</p>
                  <img width="1000" height="530" src="img/portfolio/fullsize/KUKA.gif"></img>
                  <p>Since robots are able to follow trajectories based on kinematics, this project is to plan a trajectory for the end-effector 
                    of the youBot mobile manipulator (a mobile base with four mecanum wheels and a 5R robot arm), 
                    performs odometry as the chassis moves, and performs feedback control to drive the youBot to pick up a block at a specified location,
                     carry it to a desired location, and put it down.</p>
                  <p></p>
                  <h3>Reference Trajectory Generation</h3>
                  <p>Given eight configurations indicating the relationship between end-effector, cube and world frame under different conditions, 
                    generate a reference trajectory for the gripper on frame {e}.
                    The output is written to a cvs file containing 13 attributes: r11, r12, r13, r21, r22, r23, r31, r32, r33, px, py, pz, gripper state</p>
                  <img width="242" height="100" src="img/portfolio/fullsize/Tse.png"></img>
                  <h3>Kinematics Simulator for KUKA youBot</h3>
                  <p>Given the current configuration of youBot (Chassis phi, Chassis x, Chassis y, J1, J2, J3, J4, J5, W1, W2, W3, W4, Gripper), 
                    joints speed and wheel speed, return the next configuration of the robot after a short time dt(default as 0.01s).</p>
                  <p></p>
                  <h3>Forward Control</h3>
                  <p>The feedback control of the the mobile manipulator is given by kinematic task-space feedforward plus feedback control law:</p>
                  <img width="450" height="50" src="img/portfolio/fullsize/control_law.png"></img>
                  <li>Given the current, next and actual end-effector configurations, PI controller gains, return the commanded end-effector twist V and the error list of each joint.</li>
                  <li>Given the joint angles, Body Jacobians and several other configurations, return the Jacobian of robot arm and base.</li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 11 -->
    <div class="portfolio-modal modal fade" id="portfolioModal11" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">shriekinDesparado Chatbot</h2>
                  <p class="item-intro text-muted">Conversational AI using Attention Model</p>
                  <img width="800" height="536" src="img/portfolio/fullsize/chatbot.gif"></img>
                  <h3>Introduction</h3>
                  <p>The main goal of this project is to implement a chit-chat bot using Transformer, which is a state-of-art model with Attention based on the paper 
                    from Google Brain, "<a href = "https://arxiv.org/abs/1706.03762">Attention is All You Need</a>".</p>
                  <p></p>
                  <p>Through the command line interface, a can run the eval.py script and then interact with the chatbot by typing in prompts directly on the command line. Based on the data on 
                    which the model is trained, an appropriate response will be constructed and printed at the command line.</p>
                  <h3>Data and Pre-processing</h3>
                  <p>One major part of this project is to collect and preprocess as much data as we could to feed into the model and improve the performance.
                     There are several dataset source being used for this project: <a href="http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie Dialogs Corpus</a>,
                      Twitter Chat Corpus, Ubuntu Chat Dialogues and <a href="https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/">Reddit Comment Threads</a>.</p>
                  <p>All these raw data are in different formats, size, and storage methods. In order to apply all of these data to one model, we have to pre-process them. NLTK and Regex have been the two mainly used tools for our data pre-processing.</p>
                  <p>Below is the result of an unsuccessful data-preprocessing, where the source data contains a lot of long-term complex words</p>
                  <img src="img/portfolio/fullsize/badChatbot.png"></img>
                  <h3>Attention Model</h3>
                  <p>With an attention mechanism we no longer try encode the full source sentence into a fixed-length vector. Rather, we allow the decoder 
                    to “attend” to different parts of the source sentence at each step of the output generation. Importantly, we let the model learn what to attend
                     to based on the input sentence and what it has produced so far.</p>
                  <h3>Deployment</h3>
                  <p>Using a pretrained model can expedite your chatbot experience. <a href="https://drive.google.com/open?id=1Tk3K46neJPiC2KITnt_fhLSLhBL0F8p3">Twitter Corpus Trained model</a> is a zip file with pretrained hyperparameters.
                      Simply extract it and run evalcopy.py could launch the interface of the chatbot.</p>
                  <h3>Required Packages</h3>
                  <li>Numpy, Tensorflow, NLTK, Regex, JSON, GPU(for optimized running)</li>
                  <p></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 12 -->
    <div class="portfolio-modal modal fade" id="portfolioModal12" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">HOMMIE: the Quadrotor</h2>
                  <p class="item-intro text-muted">Course Project</p>
                  <img width="800" height="450" src="img/portfolio/fullsize/quadrotor.gif"></img>
                  <h3>Introduction</h3>
                  <p>The main idea of this project is to perform real time embedded control for an autonomous electromechanical system.</p>
                  <h3>Build</h3>
                  <p>Assemble a quadrotor from commodity parts including IMU, RaspberryPi, PWM board, chassis and motors. Below is the picture of the quadrotor.</p>
                  <img width="800" height="600" src="img/portfolio/fullsize/quad.jpg"></img>
                  <h3>PID Control</h3>
                  <p>Create the software for controlling quadrotor in both high and low level.</p>
                  <p>First of all I calibrated IMU to reset the aircraft principle axes, added PID controller for pitch, roll and yaw, as well as the joystick thrust. 
                    And then finely tuned the gains so that the quad could fly smoothly without oscillation. The quad could be manipulated easily and stably by joystick commands. Here is the example of joystick control flight.</p>
                  <img width="800" height="450" src="img/portfolio/fullsize/fly.gif"></img>
                  <h3>Autonomous Flight</h3>
                  <p>The quad will receive IR light transmitted by HTC Vive Lighthouse, which could return the current X, Y, Z and theta value of the quad. 
                    I calibrated and filtered the vive sensor data to reduce noise first. Then added higher level PID controller to the offset of current coordinate above the 
                    original lower level Pitch-Roll-Yaw-Thrust controller. Finely tuned the gains to make sure the quad could hold its position at a fixed location. (Shown in the GIF at top)</p>
                  <p></p>
                  <hr>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 13 -->
    <div class="portfolio-modal modal fade" id="portfolioModal13" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-12 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2 class="text-uppercase">PinBall: Dynamic Simulation</h2>
                  <p class="item-intro text-muted">Course Project</p>
                  <img width="648" height="640" src="img/portfolio/fullsize/314.gif"></img>
                  <h3>Introduction</h3>
                  <p>The main goal of the project is to animate the movement of a triangle (or a square) bouncing freely in an enclosure space with several obstacles. 
                    The idea comes from the classic pinball game.</p>
                  <h3>Implementation</h3>
                  <p>The final system consists of two steady blocks and one rotating bar shown below. 
                    There are total of ​ 16​​ impact conditions in the whole system, four for the boundary walls, eight for each side of the blocks, 
                    and four for the vertex hitting the rotating bar. There are three configuration variables: x[t]​​, y[t]​​ representing the location 
                    of the center of the ball, and θ[t]​​ as the rotation angle of the ball.</p>
                  <p>The Euler-Lagrange Equation is:</p>
                  <img width="886" height="78" src="img/portfolio/fullsize/lag.png"></img>
                  <h3>Analysis</h3>
                  <p>In Mathematica, the system will keep track of the position and angle of the square “ball”. Whenever the vertical dimension from the center of 
                    the ball to its edge (in this case equals to l * √2 * cos[π/4 − ɑ[t]]) equals to the distance from the center of the ball to the steady impact 
                    surface, the ball would bounce against the surface. For the rotating bar, I consider it as a rotating body frame. If the body frame coordinate 
                    of any of the four vertices overlaps with the bar, the ball will also bounce back. All the impacts in this system are elastic.</p>
                  <img width="800" height="800" src="img/portfolio/fullsize/handdraw.png"></img>
                  <hr>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    
    <!-- Footer -->
    <footer class="bg-light py-5">
      <div class="container">
        <div class="small text-center text-muted">Copyright &copy; 2019 - Yuchen Wang</div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
    <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
    <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/creative.min.js"></script>

  </body>

</html>
